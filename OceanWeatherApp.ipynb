{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hollimey/capstone-application/blob/main/OceanWeatherApp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebSzmQPSDjS9"
      },
      "source": [
        "### Get User Location Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a78db619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb21494b-e7a9-43b0-bec7-e8f9f2ad3549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a U.S. location to get weather information (ex. Seattle, WA): seattle, wa\n"
          ]
        }
      ],
      "source": [
        "# get user location input (U.S. only)\n",
        "user_location = input(\"Enter a U.S. location to get weather information (ex. Seattle, WA): \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3D_nNAcDU1i"
      },
      "source": [
        "#### Convert to Coords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3894bff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab82ecbe-0a6e-4ae7-ee7b-5dd988440775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopy in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy) (2.0)\n",
            "Coordinates: 47.6038321, -122.330062\n"
          ]
        }
      ],
      "source": [
        "# use geocoding library to convert city name into lat/lon coordinates\n",
        "\n",
        "%pip install geopy\n",
        "\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.exc import GeocoderTimedOut, GeocoderUnavailable\n",
        "\n",
        "geolocator = Nominatim(user_agent=\"weather_app\")\n",
        "\n",
        "try:\n",
        "    user_location_geocoded = geolocator.geocode(user_location)\n",
        "    if user_location_geocoded:\n",
        "        latitude = user_location_geocoded.latitude\n",
        "        longitude = user_location_geocoded.longitude\n",
        "        print(f\"Coordinates: {latitude}, {longitude}\")\n",
        "    else:\n",
        "        print(f\"Location '{user_location}' not found.\")\n",
        "        latitude = None\n",
        "        longitude = None\n",
        "except (GeocoderTimedOut, GeocoderUnavailable) as e:\n",
        "    print(f\"Geocoding service error: {e}\")\n",
        "    latitude = None\n",
        "    longitude = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXxnXNpLJ7YR"
      },
      "source": [
        "### NOAA Weather Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5abf888e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ff3153-a661-43e1-da90-5e9483d8e07b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Determined state for alerts: WA\n",
            "Parsed 5 active weather alerts.\n",
            "\n",
            "Atmospheric data and alerts saved to user_data_noaa_atmos.json\n"
          ]
        }
      ],
      "source": [
        "# fetch The National Weather Service (NWS) data from API\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def fetch_weather_data(latitude, longitude):\n",
        "    point_url = f\"https://api.weather.gov/points/{latitude},{longitude}\"\n",
        "    try:\n",
        "        response = requests.get(point_url)\n",
        "        response.raise_for_status()  # http error for bad responses\n",
        "        point_data = response.json()\n",
        "\n",
        "        forecast_url = point_data['properties']['forecast']\n",
        "        hourly_forecast_url = point_data['properties']['forecastHourly']\n",
        "        gridpoints_url = f\"https://api.weather.gov/gridpoints/{point_data['properties']['gridId']}/{point_data['properties']['gridX']},{point_data['properties']['gridY']}/forecast\"\n",
        "\n",
        "        # fetch data\n",
        "        forecast_response = requests.get(forecast_url)\n",
        "        forecast_response.raise_for_status()\n",
        "        forecast_data = forecast_response.json()\n",
        "        hourly_forecast_response = requests.get(hourly_forecast_url)\n",
        "        hourly_forecast_response.raise_for_status()\n",
        "        hourly_forecast_data = hourly_forecast_response.json()\n",
        "        gridpoints_response = requests.get(gridpoints_url)\n",
        "        gridpoints_response.raise_for_status()\n",
        "        gridpoints_data = gridpoints_response.json()\n",
        "\n",
        "        # return dictionary\n",
        "        return {\n",
        "            \"point_data\": point_data,\n",
        "            \"forecast\": forecast_data,\n",
        "            \"hourly_forecast\": hourly_forecast_data,\n",
        "            \"gridpoints\": gridpoints_data\n",
        "        }\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching atmospheric data: {e}\")\n",
        "        return None\n",
        "\n",
        "weather_data_result = fetch_weather_data(latitude, longitude)\n",
        "\n",
        "# determine the state to fetch alerts\n",
        "state_code = None\n",
        "if weather_data_result and 'point_data' in weather_data_result and \\\n",
        "   'properties' in weather_data_result['point_data'] and \\\n",
        "   'relativeLocation' in weather_data_result['point_data']['properties'] and \\\n",
        "   'properties' in weather_data_result['point_data']['properties']['relativeLocation'] and \\\n",
        "   'state' in weather_data_result['point_data']['properties']['relativeLocation']['properties']:\n",
        "    state_code = weather_data_result['point_data']['properties']['relativeLocation']['properties']['state']\n",
        "    print(f\"Determined state for alerts: {state_code}\")\n",
        "else:\n",
        "    print(\"Could not determine state for fetching alerts.\")\n",
        "\n",
        "# initialize\n",
        "parsed_alerts = []\n",
        "alerts_url = None\n",
        "\n",
        "# fetch and parse alerts if state_code is available\n",
        "if state_code:\n",
        "    alerts_url = f\"https://api.weather.gov/alerts/active?area={state_code}\"\n",
        "\n",
        "    try:\n",
        "        alerts_response = requests.get(alerts_url)\n",
        "        if alerts_response.status_code == 200:\n",
        "\n",
        "            # parse json response\n",
        "            weather_alerts_data = alerts_response.json()\n",
        "            if weather_alerts_data and 'features' in weather_alerts_data:\n",
        "                for feature in weather_alerts_data['features']:\n",
        "                    if 'properties' in feature:\n",
        "                        properties = feature['properties']\n",
        "                        alert_info = {\n",
        "                            'event': properties.get('event'),\n",
        "                            'headline': properties.get('headline'),\n",
        "                            'description': properties.get('description'),\n",
        "                            'effective': properties.get('effective'),\n",
        "                            'expires': properties.get('expires')\n",
        "                        }\n",
        "                        parsed_alerts.append(alert_info)\n",
        "            print(f\"Parsed {len(parsed_alerts)} active weather alerts.\")\n",
        "        else:\n",
        "            print(f\"Error fetching weather alerts: Status code {alerts_response.status_code}\")\n",
        "            print(f\"Response content:\\n{alerts_response.text}\")\n",
        "            weather_alerts_data = None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error during weather alerts request: {e}\")\n",
        "        weather_alerts_data = None\n",
        "else:\n",
        "    print(\"State code/abbreviation not available. Cannot fetch alerts.\")\n",
        "    weather_alerts_data = None\n",
        "\n",
        "# save to json file\n",
        "if weather_data_result:\n",
        "    # remove useless \"@context\" key information:\n",
        "    # from point_data\n",
        "    if 'point_data' in weather_data_result and '@context' in weather_data_result['point_data']:\n",
        "        del weather_data_result['point_data']['@context']\n",
        "    # from forecast\n",
        "    if 'forecast' in weather_data_result and '@context' in weather_data_result['forecast']:\n",
        "        del weather_data_result['forecast']['@context']\n",
        "    # from hourly_forecast\n",
        "    if 'hourly_forecast' in weather_data_result and '@context' in weather_data_result['hourly_forecast']:\n",
        "        del weather_data_result['hourly_forecast']['@context']\n",
        "    # from gridpoints\n",
        "    if 'gridpoints' in weather_data_result and '@context' in weather_data_result['gridpoints']:\n",
        "        del weather_data_result['gridpoints']['@context']\n",
        "\n",
        "    # remove empty \"detailedForecast\" information:\n",
        "    # from hourly_forecast periods\n",
        "    if 'hourly_forecast' in weather_data_result and 'properties' in weather_data_result['hourly_forecast'] and 'periods' in weather_data_result['hourly_forecast']['properties']:\n",
        "        for period in weather_data_result['hourly_forecast']['properties']['periods']:\n",
        "            if 'detailedForecast' in period:\n",
        "                del period['detailedForecast']\n",
        "\n",
        "    # remove empty \"name\" information:\n",
        "    # from hourly_forecast periods\n",
        "    if 'hourly_forecast' in weather_data_result and 'properties' in weather_data_result['hourly_forecast'] and 'periods' in weather_data_result['hourly_forecast']['properties']:\n",
        "        for period in weather_data_result['hourly_forecast']['properties']['periods']:\n",
        "            if 'name' in period:\n",
        "                del period['name']\n",
        "\n",
        "    # remove useless \"icon\" information:\n",
        "    # from hourly_forecast periods\n",
        "    if 'hourly_forecast' in weather_data_result and 'properties' in weather_data_result['hourly_forecast'] and 'periods' in weather_data_result['hourly_forecast']['properties']:\n",
        "        for period in weather_data_result['hourly_forecast']['properties']['periods']:\n",
        "            if 'icon' in period:\n",
        "                del period['icon']\n",
        "\n",
        "    # remove empty \"temperatureTrend\" information:\n",
        "    # from gridpoints periods\n",
        "    if 'gridpoints' in weather_data_result and 'properties' in weather_data_result['gridpoints'] and 'periods' in weather_data_result['gridpoints']['properties']:\n",
        "        for period in weather_data_result['gridpoints']['properties']['periods']:\n",
        "            if 'temperatureTrend' in period:\n",
        "                del period['temperatureTrend']\n",
        "    # from hourly_forecast periods\n",
        "    if 'hourly_forecast' in weather_data_result and 'properties' in weather_data_result['hourly_forecast'] and 'periods' in weather_data_result['hourly_forecast']['properties']:\n",
        "        for period in weather_data_result['hourly_forecast']['properties']['periods']:\n",
        "            if 'temperatureTrend' in period:\n",
        "                del period['temperatureTrend']\n",
        "    # from forecast periods\n",
        "    if 'forecast' in weather_data_result and 'properties' in weather_data_result['forecast'] and 'periods' in weather_data_result['forecast']['properties']:\n",
        "        for period in weather_data_result['forecast']['properties']['periods']:\n",
        "            if 'temperatureTrend' in period:\n",
        "                del period['temperatureTrend']\n",
        "\n",
        "    # structure json file\n",
        "    weather_output = {\n",
        "        \"user_location\": {\n",
        "            \"latitude\": latitude,\n",
        "            \"longitude\": longitude,\n",
        "            \"date\": datetime.now().strftime('%Y-%m-%d')\n",
        "        },\n",
        "        \"atmospheric_data\": weather_data_result,\n",
        "        \"weather_alerts\": parsed_alerts,\n",
        "        \"alerts_source_url\": alerts_url\n",
        "    }\n",
        "    weather_file = \"user_data_noaa_atmos.json\"\n",
        "    try:\n",
        "        with open(weather_file, 'w') as f:\n",
        "            json.dump(weather_output, f, indent=4)\n",
        "        print(f\"\\nAtmospheric data and alerts saved to {weather_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving atmospheric data and alerts to JSON: {e}\")\n",
        "else:\n",
        "    print(\"Atmospheric data has not been fetched yet.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b02f8ec9"
      },
      "source": [
        "### EPA Air Quality Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e44f659",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc941f63-e164-434f-a2db-ec78075ea56f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Air quality data saved to user_data_epa_aq.json\n"
          ]
        }
      ],
      "source": [
        "# fetch AQ data from EPA API\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# note: consider adding a secure method for handling API keys later\n",
        "airnow_api_key = \"17C7530F-6ED9-40D5-8DA3-A8328CB8F1B0\"\n",
        "airnow_url = f\"https://www.airnowapi.org/aq/observation/latLong/current/?format=application/json&latitude={latitude}&longitude={longitude}&distance=25&API_KEY={airnow_api_key}\"\n",
        "\n",
        "try:\n",
        "    response = requests.get(airnow_url)\n",
        "    response.raise_for_status() # raise http error for bad responses\n",
        "    aq_data = response.json()\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching air quality data: {e}\")\n",
        "    aq_data = None\n",
        "\n",
        "# save to json file\n",
        "if aq_data:\n",
        "    aq_file = \"user_data_epa_aq.json\"\n",
        "\n",
        "    output_data = {\n",
        "        \"user_location\": {\n",
        "            \"latitude\": latitude,\n",
        "            \"longitude\": longitude,\n",
        "            \"date\": datetime.now().strftime('%Y-%m-%d')\n",
        "        },\n",
        "        \"air_quality_data\": aq_data # include fetched AQ data under a new key\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # write to json file\n",
        "        with open(aq_file, 'w') as f:\n",
        "            json.dump(output_data, f, indent=4)\n",
        "        print(f\"Air quality data saved to {aq_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving air quality data to JSON: {e}\")\n",
        "else:\n",
        "    print(\"Air quality data not available to save.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMs9YB-Nh2o1"
      },
      "source": [
        "### NOAA Buoy Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7186fde0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05497472-8b1c-4880-9072-5c360fa6aee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buoy data saved to dataset_noaa_buoy.json\n"
          ]
        }
      ],
      "source": [
        "# fetch and parse ocean buoy data\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import json\n",
        "\n",
        "buoy_url = \"https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt\"\n",
        "\n",
        "try:\n",
        "  response = requests.get(buoy_url)\n",
        "  response.raise_for_status()\n",
        "  text_content = response.text\n",
        "\n",
        "  # parse the text content into a pandas df\n",
        "  data_lines = text_content.strip().split('\\n')\n",
        "  header_line_index = -1\n",
        "  for i, line in enumerate(data_lines):\n",
        "      if line.startswith('#'):\n",
        "          header_line_index = i\n",
        "          break\n",
        "\n",
        "  if header_line_index != -1:\n",
        "      buoy_dataframe = pd.read_csv(StringIO('\\n'.join(data_lines[header_line_index:])), sep='\\s+', skiprows=[1]) # skips units row\n",
        "\n",
        "      # save to json file\n",
        "      ocean_buoy_file = \"dataset_noaa_buoy.json\"\n",
        "      try:\n",
        "          # convert df to a list of dictionaries for json serialization\n",
        "          buoy_data_list = buoy_dataframe.to_dict(orient='records')\n",
        "\n",
        "          # structure json file\n",
        "          output_data = {\n",
        "              \"buoy_observations\": buoy_data_list\n",
        "          }\n",
        "\n",
        "          with open(ocean_buoy_file, 'w') as f:\n",
        "              json.dump(output_data, f, indent=4)\n",
        "          print(f\"Buoy data saved to {ocean_buoy_file}\")\n",
        "      except Exception as e:\n",
        "          print(f\"Error saving NOAA buoy data to JSON: {e}\")\n",
        "  else:\n",
        "      print(\"Could not find header line in NOAA buoy data.\")\n",
        "      buoy_dataframe = None\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching NOAA buoy data: {e}\")\n",
        "    buoy_dataframe = None\n",
        "except Exception as e:\n",
        "    print(f\"Error parsing NOAA buoy data: {e}\")\n",
        "    buoy_dataframe = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa58acc9"
      },
      "source": [
        "#### Nearest Stations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d0c897a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0483daa-5954-461a-8333-d89143bfc3f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found data for 12 out of 14 parameters within the 80-mile radius.\n",
            "\n",
            "Nearest buoy data saved to user_data_noaa_buoy.json\n"
          ]
        }
      ],
      "source": [
        "from geopy.distance import geodesic\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "if latitude is None or longitude is None:\n",
        "    print(\"User location could not be determined.\")\n",
        "    buoy_dataframe = None\n",
        "\n",
        "# calculate distance between user and each buoy\n",
        "if buoy_dataframe is not None:\n",
        "    def calculate_distance(row):\n",
        "        station_lat = pd.to_numeric(row['LAT'], errors='coerce')\n",
        "        station_lon = pd.to_numeric(row['LON'], errors='coerce')\n",
        "\n",
        "        if pd.isna(station_lat) or pd.isna(station_lon):\n",
        "            return float('inf')\n",
        "        try:\n",
        "            user_coords = (latitude, longitude)\n",
        "            station_coords = (station_lat, station_lon)\n",
        "            return geodesic(user_coords, station_coords).miles\n",
        "        except ValueError:\n",
        "            return float('inf')\n",
        "    buoy_dataframe['Distance'] = buoy_dataframe.apply(calculate_distance, axis=1)\n",
        "    nearest_stations_df = buoy_dataframe.sort_values(by='Distance').reset_index(drop=True) # sort by distance\n",
        "\n",
        "    requested_parameters = {\n",
        "        'wind_direction': 'WDIR',\n",
        "        'wind_speed': 'WSPD',\n",
        "        'wind_gust': 'GST',\n",
        "        'wave_height': 'WVHT',\n",
        "        'dominant_wave_period': 'DPD',\n",
        "        'avg_wave_period': 'APD',\n",
        "        'mean_wave_direction': 'MWD',\n",
        "        'atmos_pressure': 'PRES',\n",
        "        'pressure_tendency': 'PTDY',\n",
        "        'air_temp': 'ATMP',\n",
        "        'water_temp': 'WTMP',\n",
        "        'dewpoint_temp': 'DEWP',\n",
        "        'visibility': 'VIS',\n",
        "        'tide': 'TIDE'\n",
        "    }\n",
        "\n",
        "    extracted_data = {}\n",
        "    parameters_found = {\n",
        "        param: False for param in requested_parameters.keys()\n",
        "        }\n",
        "    searched_stations = []\n",
        "    search_radius = 80 # define the search radius\n",
        "\n",
        "    # iterate through stations starting from the nearest\n",
        "    for index, station in nearest_stations_df.iterrows():\n",
        "        station_id = station['#STN']\n",
        "        station_distance = round(station['Distance'], 2) # round distance\n",
        "\n",
        "        # check if the station is within radius\n",
        "        if station_distance <= search_radius:\n",
        "            searched_stations.append({'id': station_id, 'distance': station_distance})\n",
        "            all_found_for_this_station = True\n",
        "\n",
        "            for param_name, col_name in requested_parameters.items():\n",
        "                if not parameters_found[param_name]:\n",
        "                    param_value = station.get(col_name)\n",
        "\n",
        "                    if pd.notna(param_value) and str(param_value).strip().upper() != 'MM':\n",
        "                        measurement_unit = parameter_metadata.get(col_name, \"\").split('(')[-1].replace(')', '')\n",
        "\n",
        "                        try:\n",
        "                            year = int(station.get('YYYY'))\n",
        "                            month = int(station.get('MM'))\n",
        "                            day = int(station.get('DD'))\n",
        "                            hour = int(station.get('hh'))\n",
        "                            minute = int(station.get('mm'))\n",
        "                            observation_time_lst = datetime(year, month, day, hour, minute).strftime('%Y-%m-%d %H:%M:%S')\n",
        "                        except (ValueError, TypeError):\n",
        "                            observation_time_lst = \"N/A\"\n",
        "\n",
        "                        extracted_data[param_name] = {\n",
        "                            'value': param_value,\n",
        "                            'unit': measurement_unit.strip(),\n",
        "                            'station_id': station_id,\n",
        "                            'station_latitude': station.get('LAT'),\n",
        "                            'station_longitude': station.get('LON'),\n",
        "                            'time_LST': observation_time_lst,\n",
        "                            'distance_miles': station_distance\n",
        "                            }\n",
        "                        parameters_found[param_name] = True\n",
        "                    else:\n",
        "                       all_found_for_for_this_station = False\n",
        "            if all(parameters_found.values()):\n",
        "                print(\"All requested parameters found within the 80-mile radius.\")\n",
        "                break # exits loop when all parameters are found\n",
        "        else:\n",
        "            break # stops when exceeds radius\n",
        "\n",
        "    # count the number of parameters found\n",
        "    num_parameters_found = sum(parameters_found.values())\n",
        "    total_parameters = len(requested_parameters)\n",
        "    print(f\"Found data for {num_parameters_found} out of {total_parameters} parameters within the {search_radius}-mile radius.\")\n",
        "\n",
        "    # identify missing parameters\n",
        "    missing_params = [param for param, found in parameters_found.items() if not found]\n",
        "\n",
        "    # structure json file\n",
        "    final_output = {\n",
        "        \"user_location\": {\n",
        "            \"latitude\": latitude,\n",
        "            \"longitude\": longitude,\n",
        "            \"date\": datetime.now().strftime('%Y-%m-%d')\n",
        "        },\n",
        "        \"extracted_buoy_data\": extracted_data,\n",
        "        \"search_radius_miles\": search_radius,\n",
        "        \"missing_parameters\": missing_params,\n",
        "        \"searched_stations_within_radius\": searched_stations\n",
        "    }\n",
        "\n",
        "    # save json file\n",
        "    if final_output:\n",
        "        output_filename = \"user_data_noaa_buoy.json\"\n",
        "        try:\n",
        "            with open(output_filename, 'w') as f:\n",
        "                json.dump(final_output, f, indent=4)\n",
        "            print(f\"\\nNearest buoy data saved to {output_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving nearest buoy data to JSON: {e}\")\n",
        "    else:\n",
        "        print(\"No nearest buoy data available to save.\")\n",
        "else:\n",
        "    print(\"Buoy data is not available to extract data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gaYomvD7Yb7"
      },
      "source": [
        "### CO-OPS Stations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b982d2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89766d82-c92c-4fcb-a822-e4f80cef7b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 301 stations from: https://api.tidesandcurrents.noaa.gov/mdapi/prod/webapi/stations.json\n",
            "Fetched 381 stations from: https://opendap.co-ops.nos.noaa.gov/stations/stationsXML.jsp\n",
            "\n",
            "CO-OPS stations saved to dataset_noaa_coops.json\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "stations_json_url = \"https://api.tidesandcurrents.noaa.gov/mdapi/prod/webapi/stations.json\"\n",
        "stations_xml_url = \"https://opendap.co-ops.nos.noaa.gov/stations/stationsXML.jsp\"\n",
        "\n",
        "try:\n",
        "    # stations from JSON source\n",
        "    response = requests.get(stations_json_url)\n",
        "    response.raise_for_status()\n",
        "    stations_data = response.json()\n",
        "\n",
        "    if stations_data and 'stations' in stations_data and isinstance(stations_data['stations'], list):\n",
        "        stations_df = pd.DataFrame(stations_data['stations'])\n",
        "        print(f\"Fetched {len(stations_df)} stations from: {stations_json_url}\")\n",
        "\n",
        "        selected_columns_df = stations_df[['id', 'name', 'state', 'lng', 'lat']].copy()\n",
        "        selected_columns_df = selected_columns_df.rename(columns={\n",
        "            'id': 'station_id',\n",
        "            'name': 'Station Name',\n",
        "            'state': 'State',\n",
        "            'lng': 'Longitude',\n",
        "            'lat': 'Latitude'\n",
        "        })\n",
        "\n",
        "        selected_columns_df['City, State'] = selected_columns_df['Station Name'] + ', ' + selected_columns_df['State']\n",
        "        formatted_stations_df = selected_columns_df[['station_id', 'City, State', 'Longitude', 'Latitude']]\n",
        "    else:\n",
        "        print(\"JSON data does not contain a list under the key 'stations'.\")\n",
        "        stations_df = pd.DataFrame()\n",
        "        formatted_stations_df = pd.DataFrame()\n",
        "\n",
        "    # stations from XML source\n",
        "    xml_response = requests.get(stations_xml_url)\n",
        "    xml_response.raise_for_status()\n",
        "    soup = BeautifulSoup(xml_response.content, \"xml\")\n",
        "\n",
        "    xml_stations = []\n",
        "    for st in soup.find_all(\"station\"):\n",
        "        xml_stations.append({\n",
        "            \"station_id\": st.get(\"ID\"),\n",
        "            \"Owner\": st.get(\"Owner\"),\n",
        "            \"Type\": st.get(\"Type\"),\n",
        "            \"Status\": st.get(\"Status\")\n",
        "        })\n",
        "\n",
        "    xml_df = pd.DataFrame(xml_stations)\n",
        "    print(f\"Fetched {len(xml_df)} stations from: {stations_xml_url}\")\n",
        "\n",
        "    # merge data\n",
        "    merged_nearby_stations_df = pd.merge(formatted_stations_df, xml_df, on=\"station_id\", how=\"left\")\n",
        "\n",
        "    # remove empty 'Owner', 'Type', and 'Status' columns\n",
        "    columns_to_drop = ['Owner', 'Type', 'Status']\n",
        "    merged_nearby_stations_df = merged_nearby_stations_df.drop(columns=columns_to_drop, errors='ignore') # if columns don't exist\n",
        "\n",
        "    # save json file\n",
        "    output_filename = \"dataset_noaa_coops.json\"\n",
        "    try:\n",
        "        merged_data_json = merged_nearby_stations_df.to_dict(orient='records')\n",
        "\n",
        "        # structure json file\n",
        "        output_data = {\n",
        "            \"datasets\": {\n",
        "                \"sources\": [stations_json_url, stations_xml_url],\n",
        "                \"total_stations_listed\": len(merged_nearby_stations_df) if not merged_nearby_stations_df.empty else 0,\n",
        "                \"description\": {\n",
        "                  \"about\": \"Maintained by the National Oceanic and Atmospheric Administration's (NOAA), Center for Operational Oceanographic Products and Services (CO-OPS). Provided is a list of active National Water Level Observation Network (NWLON) stations with some sensor configurations. More information can be found through https://opendap.co-ops.nos.noaa.gov/stations/index.jsp\"\n",
        "                },\n",
        "            \"station_list\": merged_data_json\n",
        "            },\n",
        "        }\n",
        "\n",
        "        with open(output_filename, 'w') as f:\n",
        "            json.dump(output_data, f, indent=4)\n",
        "        print(f\"\\nCO-OPS stations saved to {output_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving merged CO-OPS station data to JSON: {e}\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching data: {e}\")\n",
        "    stations_df = pd.DataFrame()\n",
        "    formatted_stations_df = pd.DataFrame()\n",
        "    merged_nearby_stations_df = pd.DataFrame()\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Error decoding JSON: {e}\")\n",
        "    stations_df = pd.DataFrame()\n",
        "    formatted_stations_df = pd.DataFrame()\n",
        "    merged_nearby_stations_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nearest Stations"
      ],
      "metadata": {
        "id": "PcHeXSXPlVfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from geopy.distance import geodesic\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# confirm user location\n",
        "if 'latitude' not in globals() or latitude is None or 'longitude' not in globals() or longitude is None:\n",
        "    print(\"User location (latitude or longitude) not available. Cannot filter stations by proximity.\")\n",
        "elif 'formatted_stations_df' not in globals() or formatted_stations_df.empty:\n",
        "    print(\"Formatted stations data is not available. Cannot filter stations.\")\n",
        "else:\n",
        "    user_coords = (latitude, longitude)\n",
        "    proximity_miles = 80\n",
        "\n",
        "    # calculate distance from user to each station\n",
        "    stations_for_distance_calc = formatted_stations_df.copy()\n",
        "    stations_for_distance_calc['Latitude'] = pd.to_numeric(stations_for_distance_calc['Latitude'], errors='coerce')\n",
        "    stations_for_distance_calc['Longitude'] = pd.to_numeric(stations_for_distance_calc['Longitude'], errors='coerce')\n",
        "\n",
        "    stations_for_distance_calc.dropna(subset=['Latitude', 'Longitude'], inplace=True) # drop lat/lon rows that could not be converted to numeric\n",
        "\n",
        "    def calculate_distance_miles(row):\n",
        "        station_coords = (row['Latitude'], row['Longitude'])\n",
        "        try:\n",
        "            return geodesic(user_coords, station_coords).miles\n",
        "        except ValueError:\n",
        "            return float('inf') # handles invalid coords\n",
        "\n",
        "    stations_for_distance_calc['distance_miles'] = stations_for_distance_calc.apply(calculate_distance_miles, axis=1)\n",
        "\n",
        "    # filter for stations within the specified proximity\n",
        "    merged_nearby_stations_df = stations_for_distance_calc[stations_for_distance_calc['distance_miles'] <= proximity_miles].sort_values(by='distance_miles')\n",
        "\n",
        "    if not merged_nearby_stations_df.empty:\n",
        "        merged_nearby_stations_df['distance_miles'] = merged_nearby_stations_df['distance_miles'].round(2)\n",
        "\n",
        "        # save json file\n",
        "        output_filename = \"user_data_noaa_coops_stations.json\"\n",
        "        try:\n",
        "            nearby_stations_json = merged_nearby_stations_df.to_dict(orient='records')\n",
        "\n",
        "            # structure json file\n",
        "            output_data = {\n",
        "                \"user_location\": {\n",
        "                    \"latitude\": latitude,\n",
        "                    \"longitude\": longitude,\n",
        "                    \"date\": datetime.now().strftime('%Y-%m-%d')\n",
        "                },\n",
        "                \"coops_stations\": {\n",
        "                    \"source_url\": stations_json_url,\n",
        "                    \"within_proximity_miles\": proximity_miles,\n",
        "                    \"total_stations_within_proximity\": len(merged_nearby_stations_df),\n",
        "                    \"nearby\": {\n",
        "                        \"stations\": merged_nearby_stations_df.to_dict(orient='records')\n",
        "                    },\n",
        "                },\n",
        "            }\n",
        "\n",
        "            with open(output_filename, 'w') as f:\n",
        "                json.dump(output_data, f, indent=4)\n",
        "            print(f\"Nearby CO-OPS stations saved to {output_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving nearby CO-OPS station data to JSON: {e}\")\n",
        "    else:\n",
        "        print(\"No CO-OPS stations found within the specified proximity.\")"
      ],
      "metadata": {
        "id": "GwfMQuXxkKtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b93d8ef-bc4b-47be-b5e2-822bfff32ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nearby CO-OPS stations saved to user_data_noaa_coops_stations.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tide Predictions"
      ],
      "metadata": {
        "id": "PqQHIozNutOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch tide predictions from CO-OPS API\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "\n",
        "if 'merged_nearby_stations_df' not in globals() or merged_nearby_stations_df.empty:\n",
        "    print(\"Nearby CO-OPS stations are unavailable at this time.\")\n",
        "else:\n",
        "    today = datetime.now() # date range for yesterday and today\n",
        "    yesterday = today - timedelta(days=1)\n",
        "\n",
        "    begin_date_str = yesterday.strftime('%Y%m%d')\n",
        "    end_date_str = today.strftime('%Y%m%d') # format string YYYYMMDD\n",
        "\n",
        "    tide_predictions_url = \"https://api.tidesandcurrents.noaa.gov/api/prod/datagetter\"\n",
        "\n",
        "    about_tides = \"Tides refer to the rising and falling of the sea. Which is caused by the gravitational pull of the moon and the sun. Tides are very long-period waves that move through the ocean and progress toward the coastlines where they appear as the regular rise and fall of the sea surface. Tide predictions provide the times and heights for the astronomical tides. Predictions are based on the analysis of data collected at coastal locations maintained by the National Oceanic and Atmospheric Administration's (NOAA), Center for Operational Oceanographic Products and Services (CO-OPS). CO-OPS maintains the National Water Level Observation Network (NWLON), an observation network with more than 200 permanent water level stations on the coasts and Great Lakes.This system allows NOAA to provide the official tidal predictions for the nation. Accurate water level data is critical for safe and efficient marine navigation and for the protection of infrastructure along the coast.Harmonic stations are locations with enough long-term tide data to establish harmonic constants and tidal datums. Predictions for these stations are based solely on the analysis of that data. Because predictions at these locations are based on harmonic constants, predictions can be generated for any interval, and can be adjusted to different tidal datums. CO-OPS has preselected the most common intervals (hourly, 15- and 6-minute) for data queries. Learn more through https://tidesandcurrents.noaa.gov/water_level_info.html or https://tidesandcurrents.noaa.gov/education/tech-assist/training/user-guides/assets/pdfs/Tide_Predictions_User_Guide_v4.pdf\"\n",
        "\n",
        "    # initialize variables\n",
        "    tide_predictions_result = None\n",
        "    found_data = False\n",
        "    nearest_station_info = None\n",
        "\n",
        "    # iterate through nearby stations to find one with tide predictions\n",
        "    for index, station in merged_nearby_stations_df.iterrows():\n",
        "        nearest_station_id = station['station_id']\n",
        "\n",
        "        # API request parameters\n",
        "        params = {\n",
        "            'product': 'predictions',\n",
        "            'application': 'NOS.COOPS.TAC.WL',\n",
        "            'begin_date': begin_date_str,\n",
        "            'end_date': end_date_str,\n",
        "            'datum': 'MLLW',\n",
        "            'station': nearest_station_id,\n",
        "            'time_zone': 'lst_ldt', # local time with daylight saving\n",
        "            'units': 'english',\n",
        "            'interval': '', # leave interval empty for all predictions\n",
        "            'format': 'json'\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(tide_predictions_url, params=params)\n",
        "            if response.status_code == 200:\n",
        "\n",
        "                 # parse the JSON response\n",
        "                 tide_predictions_data = response.json()\n",
        "                 tide_predictions_result = tide_predictions_data\n",
        "\n",
        "                 # check if data is available in the response\n",
        "                 if tide_predictions_result and 'predictions' in tide_predictions_result and tide_predictions_result['predictions']:\n",
        "\n",
        "                    nearest_station_info = {\n",
        "                        \"station_id\": nearest_station_id,\n",
        "                        \"station_name\": station.get('City, State', 'N/A'),\n",
        "                        \"distance_miles\": round(station.get('distance_miles', float('inf')), 2),\n",
        "                        \"latitude\": station.get('Latitude', 'N/A'),\n",
        "                        \"longitude\": station.get('Longitude', 'N/A'),\n",
        "                        \"source_url\": response.url\n",
        "                    }\n",
        "                    found_data = True\n",
        "                    break\n",
        "            else:\n",
        "                print(f\"Error fetching tide predictions from station {nearest_station_id}: Status code {response.status_code}\")\n",
        "                print(f\"Response content:\\n{response.text}\")\n",
        "                tide_predictions_result = None # store None if fetch fails\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error during tide prediction request for station {nearest_station_id}: {e}\")\n",
        "            tide_predictions_result = None # store None if request fails\n",
        "\n",
        "    # check if data was found after iterating through stations\n",
        "    if found_data:\n",
        "        reformatted_predictions = []\n",
        "        if tide_predictions_result and 'predictions' in tide_predictions_result:\n",
        "            predictions_list = tide_predictions_result['predictions']\n",
        "\n",
        "            if predictions_list:\n",
        "\n",
        "                # save json file\n",
        "                output_filename = \"user_data_noaa_coops_tide.json\"\n",
        "\n",
        "                try:\n",
        "                    reformatted_predictions = []\n",
        "                    for prediction in predictions_list:\n",
        "                        reformatted_predictions.append({\n",
        "                            \"time_LST\": prediction.get('t'),\n",
        "                            \"water_level_ft\": prediction.get('v')\n",
        "                        })\n",
        "\n",
        "                    # structure json file\n",
        "                    output_data = {\n",
        "                        \"user_location\": {\n",
        "                            \"latitude\": latitude,\n",
        "                            \"longitude\": longitude,\n",
        "                            \"date\": datetime.now().strftime('%Y-%m-%d')\n",
        "                        },\n",
        "                        \"tide_predictions\": {\n",
        "                            \"background\": {\n",
        "                                \"about\": about_tides,\n",
        "                                \"nearest_station\": {\n",
        "                                  \"station_info\": nearest_station_info,\n",
        "                                  \"data\": {\n",
        "                                    \"predictions\": reformatted_predictions\n",
        "                                },\n",
        "                              },\n",
        "                            },\n",
        "                          },\n",
        "                        }\n",
        "\n",
        "                    with open(output_filename, 'w') as f:\n",
        "                        json.dump(output_data, f, indent=4, ensure_ascii=False)\n",
        "                    print(f\"Tide prediction data saved to {output_filename}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error saving tide prediction data to JSON: {e}\")\n",
        "    else:\n",
        "        print(\"No tide predictions found for nearby CO-OPS stations.\")"
      ],
      "metadata": {
        "id": "3S7XReV2sYLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2952b4d6-6882-4e5a-821b-c0d71317f002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tide prediction data saved to user_data_noaa_coops_tide.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Water Level"
      ],
      "metadata": {
        "id": "6vy-uZ1oxag5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch water level observations from CO-OPS API\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "\n",
        "if 'merged_nearby_stations_df' not in globals() or merged_nearby_stations_df.empty:\n",
        "    print(\"Nearby CO-OPS stations data is not available. Cannot fetch water level data.\")\n",
        "else:\n",
        "    end_date = datetime.now()\n",
        "    begin_date = end_date - timedelta(days=1) # last 24 hours date range\n",
        "\n",
        "    begin_date_str = begin_date.strftime('%Y%m%d') # string format YYYYMMDD\n",
        "    end_date_str = end_date.strftime('%Y%m%d')\n",
        "\n",
        "    water_level_url = \"https://api.tidesandcurrents.noaa.gov/api/prod/datagetter\"\n",
        "\n",
        "    # initialize variables\n",
        "    water_level_result = None\n",
        "    found_data = False\n",
        "\n",
        "    # iterate through nearby stations to find one with water level data\n",
        "    for index, station in merged_nearby_stations_df.iterrows():\n",
        "        nearest_station_id = station['station_id']\n",
        "\n",
        "        # API request parameters\n",
        "        params = {\n",
        "            'product': 'water_level',\n",
        "            'application': 'NOS.COOPS.TAC.WL',\n",
        "            'begin_date': begin_date_str,\n",
        "            'end_date': end_date_str,\n",
        "            'datum': 'MLLW',\n",
        "            'station': nearest_station_id,\n",
        "            'time_zone': 'lst', # using local standard time\n",
        "            'units': 'english',\n",
        "            'format': 'json',\n",
        "            'interval': '6', # updates data at 6-minute intervals\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(water_level_url, params=params)\n",
        "            if response.status_code == 200:\n",
        "\n",
        "                # parse the json response\n",
        "                water_level_data = response.json()\n",
        "                water_level_result = water_level_data\n",
        "\n",
        "                # check if data is available in the response\n",
        "                if water_level_result and 'data' in water_level_result and water_level_result['data']:\n",
        "\n",
        "                    # reformat keys\n",
        "                    reformatted_data = []\n",
        "                    for entry in water_level_result['data']:\n",
        "                        reformatted_entry = {\n",
        "                            \"time_LST\": entry.get('t'),\n",
        "                            \"water_level_ft\": entry.get('v'),\n",
        "                            \"sigma\": entry.get('s'),\n",
        "                            \"quality_flags\": entry.get('f'),\n",
        "                            \"quality_control_flag\": entry.get('q')\n",
        "                        }\n",
        "                        reformatted_data.append(reformatted_entry)\n",
        "\n",
        "                    # structure json file\n",
        "                    output_data = {\n",
        "                        \"user_location\": {\n",
        "                            \"latitude\": latitude,\n",
        "                            \"longitude\": longitude,\n",
        "                            \"date\": datetime.now().strftime('%Y-%m-%d')\n",
        "                        },\n",
        "                        \"water_level\": {\n",
        "                            \"station_info\": {\n",
        "                                \"station_id\": nearest_station_id,\n",
        "                                \"station_name\": station.get('City, State', 'N/A'),\n",
        "                                \"distance_miles\": round(station.get('distance_miles', float('inf')), 2),\n",
        "                                \"latitude\": station.get('Latitude', 'N/A'),\n",
        "                                \"longitude\": station.get('Longitude', 'N/A'),\n",
        "                                \"source_url\": response.url\n",
        "                            },\n",
        "                              \"data\": reformatted_data\n",
        "                        },\n",
        "                    }\n",
        "\n",
        "                    # save json file\n",
        "                    output_filename = \"user_data_noaa_coops_waterlevel.json\"\n",
        "                    try:\n",
        "                        with open(output_filename, 'w') as f:\n",
        "                            json.dump(output_data, f, indent=4)\n",
        "                        print(f\"Water level observation data saved to {output_filename}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error saving water level observation data to JSON: {e}\")\n",
        "\n",
        "                    found_data = True\n",
        "                    break\n",
        "                else:\n",
        "                     print(f\"No water level data available for station {nearest_station_id}.\")\n",
        "            else:\n",
        "                print(f\"Error fetching water level data: Status code {response.status_code}\")\n",
        "                print(f\"Response content:\\n{response.text}\")\n",
        "                water_level_result = None # store None if fetch fails\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error during water level data request for station {nearest_station_id}: {e}\")\n",
        "            water_level_result = None # store None if request fails\n",
        "    if not found_data:\n",
        "        print(\"Could not find water level observations from any nearby CO-OPS station.\")"
      ],
      "metadata": {
        "id": "RYReABw0vkt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f16ee66-acc6-4070-d117-b4ec84fdb6c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Water level observation data saved to user_data_noaa_coops_waterlevel.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Air Temp"
      ],
      "metadata": {
        "id": "_WBSjf3EzW_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch air temperature data from CO-OPS API\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "\n",
        "if 'merged_nearby_stations_df' not in globals() or merged_nearby_stations_df.empty:\n",
        "    print(\"Nearby CO-OPS stations data is not available. Cannot fetch air temperature data.\")\n",
        "else:\n",
        "    today = datetime.now()\n",
        "    begin_date_str = today.strftime('%Y%m%d')\n",
        "    end_date_str = today.strftime('%Y%m%d')\n",
        "\n",
        "    air_temp_url = \"https://api.tidesandcurrents.noaa.gov/api/prod/datagetter\"\n",
        "\n",
        "    # initialize variables\n",
        "    air_temp_result = None\n",
        "    found_data = False\n",
        "    nearest_station_info = None\n",
        "\n",
        "    # iterate through nearby stations to find one with air temp data\n",
        "    for index, station in merged_nearby_stations_df.iterrows():\n",
        "        nearest_station_id = station['station_id']\n",
        "\n",
        "        # API request parameters\n",
        "        params = {\n",
        "            'product': 'air_temperature',\n",
        "            'application': 'NOS.COOPS.TAC.MET',\n",
        "            'begin_date': begin_date_str,\n",
        "            'end_date': end_date_str,\n",
        "            'station': nearest_station_id,\n",
        "            'units': 'metric',\n",
        "            'time_zone': 'lst',\n",
        "            'format': 'json',\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(air_temp_url, params=params)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                air_temp_data = response.json()\n",
        "                if air_temp_data and 'data' in air_temp_data and air_temp_data['data']:\n",
        "                    air_temp_result = air_temp_data\n",
        "\n",
        "                    nearest_station_info = {\n",
        "                        \"station_id\": nearest_station_id,\n",
        "                        \"station_name\": station.get('City, State', 'N/A'),\n",
        "                        \"distance_miles\": round(station.get('distance_miles', float('inf')), 2),\n",
        "                        \"latitude\": station.get('Latitude', 'N/A'),\n",
        "                        \"longitude\": station.get('Longitude', 'N/A'),\n",
        "                        \"source_url\": response.url\n",
        "                    }\n",
        "                    found_data = True\n",
        "                    break\n",
        "            else:\n",
        "                print(f\"Error fetching air temperature data from station {nearest_station_id}: Status code {response.status_code}\")\n",
        "                print(f\"Response content:\\n{response.text}\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error during air temperature data request for station {nearest_station_id}: {e}\")\n",
        "\n",
        "    if found_data:\n",
        "        if air_temp_result and 'data' in air_temp_result:\n",
        "            air_temp_list = air_temp_result['data']\n",
        "            if air_temp_list:\n",
        "\n",
        "                # save json file\n",
        "                output_filename = \"user_data_noaa_coops_airtemp.json\"\n",
        "                try:\n",
        "                    reformatted_data = []\n",
        "                    for entry in air_temp_list:\n",
        "                        temp_celsius = float(entry.get('v')) if entry.get('v') is not None else None\n",
        "                        temp_fahrenheit = (temp_celsius * 9/5) + 32 if temp_celsius is not None else None\n",
        "\n",
        "                        reformatted_data.append({\n",
        "                            \"time_LST\": entry.get('t'),\n",
        "                            \"temp_fahrenheit\": temp_fahrenheit,\n",
        "                            \"quality_flags\": entry.get('f')\n",
        "                        })\n",
        "\n",
        "                    # structure json file\n",
        "                    output_data = {\n",
        "                        \"user_location\": {\n",
        "                            \"latitude\": latitude,\n",
        "                            \"longitude\": longitude,\n",
        "                            \"date\": datetime.now().strftime('%Y-%m-%d')\n",
        "                        },\n",
        "                        \"air_temperature\": {\n",
        "                            \"station_info\": nearest_station_info,\n",
        "                            \"data\": reformatted_data\n",
        "                        },\n",
        "                    }\n",
        "\n",
        "                    with open(output_filename, 'w') as f:\n",
        "                        json.dump(output_data, f, indent=4)\n",
        "                    print(f\"Air temperature data saved to {output_filename}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error saving air temperature data to JSON: {e}\")\n",
        "    else:\n",
        "        print(\"No air temperatures found for nearby CO-OPS stations.\")"
      ],
      "metadata": {
        "id": "RTHz1uzMzWsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105048fb-508b-4aed-c771-ba4529e6d8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Air temperature data saved to user_data_noaa_coops_airtemp.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Water Temp"
      ],
      "metadata": {
        "id": "m0KH5ZoR3CDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch water temperature data from CO-OPS API\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "\n",
        "if 'merged_nearby_stations_df' not in globals() or merged_nearby_stations_df.empty:\n",
        "    print(\"Nearby station for CO-OPS data is not available. Cannot fetch water temperature data.\")\n",
        "else:\n",
        "    today = datetime.now()\n",
        "    begin_date_str = today.strftime('%Y%m%d')\n",
        "    end_date_str = today.strftime('%Y%m%d')\n",
        "\n",
        "    water_temp_url = \"https://api.tidesandcurrents.noaa.gov/api/prod/datagetter\"\n",
        "\n",
        "    # initialize variables\n",
        "    water_temp_result = None\n",
        "    found_data = False\n",
        "    nearest_station_info = None\n",
        "\n",
        "    # iterate through nearby stations to find one with data\n",
        "    for index, station in merged_nearby_stations_df.iterrows():\n",
        "        nearest_station_id = station['station_id']\n",
        "\n",
        "        # parameters for the API request\n",
        "        params = {\n",
        "            'product': 'water_temperature',\n",
        "            'application': 'NOS.COOPS.TAC.PHYSOCEAN',\n",
        "            'begin_date': begin_date_str,\n",
        "            'end_date': end_date_str,\n",
        "            'station': nearest_station_id,\n",
        "            'units': 'english',\n",
        "            'time_zone': 'lst',\n",
        "            'format': 'json',\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(water_temp_url, params=params)\n",
        "            if response.status_code == 200:\n",
        "                water_temp_data = response.json()\n",
        "                if water_temp_data and 'data' in water_temp_data and water_temp_data['data']:\n",
        "                    water_temp_result = water_temp_data\n",
        "\n",
        "                    nearest_station_info = {\n",
        "                        \"station_id\": nearest_station_id,\n",
        "                        \"station_name\": station.get('City, State', 'N/A'),\n",
        "                        \"distance_miles\": round(station.get('distance_miles', float('inf')), 2),\n",
        "                        \"latitude\": station.get('Latitude', 'N/A'),\n",
        "                        \"longitude\": station.get('Longitude', 'N/A'),\n",
        "                        \"source_url\": response.url\n",
        "                    }\n",
        "                    found_data = True\n",
        "                    break\n",
        "            else:\n",
        "                print(f\"Error fetching water temperature data from station {nearest_station_id}: Status code {response.status_code}\")\n",
        "                print(f\"Response content:\\n{response.text}\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error during water temperature data request for station {nearest_station_id}: {e}\")\n",
        "\n",
        "    if found_data:\n",
        "        reformatted_water_temp = []\n",
        "        if water_temp_result and 'data' in water_temp_result:\n",
        "            for entry in water_temp_result['data']:\n",
        "                reformatted_water_temp.append({\n",
        "                    \"time_LST\": entry.get('t'),\n",
        "                    \"value\": entry.get('v'), # do not change name\n",
        "                    \"quality_flags\": entry.get('f'),\n",
        "                    \"quality_control\": entry.get('q')\n",
        "                })\n",
        "\n",
        "        # structure json file\n",
        "        output_data = {\n",
        "            \"user_location\": {\n",
        "                \"latitude\": latitude,\n",
        "                \"longitude\": longitude,\n",
        "                \"date\": datetime.now().strftime('%Y-%m-%d')\n",
        "            },\n",
        "            \"water_temperature\": {\n",
        "                \"station_info\": nearest_station_info,\n",
        "                \"data\": reformatted_water_temp\n",
        "            },\n",
        "        }\n",
        "\n",
        "        # save json file\n",
        "        output_filename = \"user_data_noaa_coops_watertemp.json\"\n",
        "        try:\n",
        "            with open(output_filename, 'w') as f:\n",
        "                json.dump(output_data, f, indent=4)\n",
        "            print(f\"Water temperature data saved to {output_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving water temperatures to JSON: {e}\")\n",
        "    else:\n",
        "        print(\"No water temperatures found for nearby CO-OPS stations.\")"
      ],
      "metadata": {
        "id": "LYf0EYI-BEmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63850a59-90e6-4366-92bd-518bfdd3e921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Water temperature data saved to user_data_noaa_coops_watertemp.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Air Temp, Water Temp, Winds, Rain, Water Height\n"
      ],
      "metadata": {
        "id": "mJb7_NMLImY3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "190b4c77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9eaad97-14ba-41a1-efa6-706195ec0ad4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meteorological data saved to user_data_noaa_sos.json\n"
          ]
        }
      ],
      "source": [
        "# meteorological observations from CO-OPS Sensor Observation Service (SOS)\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "\n",
        "sos_url = \"https://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS\"\n",
        "\n",
        "observed_properties = [\"air_temperature\", \"winds\", \"rain_fall\", \"water_surface_height_above_reference_datum\", \"sea_water_temperature\"]\n",
        "\n",
        "# use nearest stations from merged_nearby_stations_df\n",
        "if 'merged_nearby_stations_df' in globals() and not merged_nearby_stations_df.empty:\n",
        "    # first five stations\n",
        "    stations_ids = merged_nearby_stations_df['station_id'].tolist()[:5]\n",
        "else:\n",
        "    print(\"Nearest CO-OPS stations data is not available. Cannot fetch meteorological data.\")\n",
        "    stations_ids = []\n",
        "\n",
        "today = datetime.now()\n",
        "begin_date_str = today.strftime('%Y-%m-%d')\n",
        "end_date_str = today.strftime('%Y-%m-%d')\n",
        "\n",
        "response_format = \"csv\"\n",
        "structured_met_data = {prop: {} for prop in observed_properties}\n",
        "\n",
        "# construct string\n",
        "event_time_string = f\"{begin_date_str}T00:00:00Z/{end_date_str}T23:59:59Z\"\n",
        "\n",
        "if stations_ids:\n",
        "    # iterate through observed properties and stations to fetch data\n",
        "    for prop in observed_properties:\n",
        "        for station_id in stations_ids:\n",
        "            offering_string = f\"urn:ioos:station:NOAA.NOS.CO-OPS:{station_id}\"\n",
        "\n",
        "            api_url = (\n",
        "                f\"{sos_url}?service=SOS&request=GetObservation&version=1.0.0\"\n",
        "                f\"&observedProperty={prop}\"\n",
        "                f\"&offering={offering_string}\"\n",
        "                f\"&eventTime={event_time_string}\"\n",
        "                f\"&responseFormat=text/{response_format}\"\n",
        "            )\n",
        "\n",
        "            try:\n",
        "                response = requests.get(api_url)\n",
        "                if response.status_code == 200:\n",
        "\n",
        "                    # read content into a pandas df if format is CSV\n",
        "                    if response_format.lower() == 'csv':\n",
        "                        try:\n",
        "                            df = pd.read_csv(StringIO(response.text), comment='#')\n",
        "\n",
        "                            # store df in the new structured dictionary\n",
        "                            structured_met_data[prop][station_id] = df.to_dict(orient='records')\n",
        "\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error parsing CSV data for {prop} at station {station_id}: {e}\")\n",
        "                            print(\"Response content head:\")\n",
        "                            print(response.text[:500])\n",
        "                    else:\n",
        "                        print(f\"Fetched data for {prop} at station {station_id} (non-CSV format):\")\n",
        "                        print(response.text[:500])\n",
        "                else:\n",
        "                    print(f\"Error fetching data for {prop} at station {station_id}: Status code {response.status_code}\")\n",
        "                    print(f\"Response content:\\n{response.text}\")\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"Error during data request for {prop} at station {station_id}: {e}\")\n",
        "else:\n",
        "    print(\"No stations available to fetch meteorological data.\")\n",
        "\n",
        "# save to json file\n",
        "if any(structured_met_data[prop] for prop in observed_properties):\n",
        "    output_filename = \"user_data_noaa_sos.json\"\n",
        "\n",
        "    # structure json file\n",
        "    output_data = {\n",
        "        \"description\": {\n",
        "            \"about\": \"The meteorological observations provided comes from the National Oceanic and Atmospheric Administration's (NOAA), Center for Operational Oceanographic Products and Services (CO-OPS), Sensor Observation Service (SOS). Learn more through # https://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/\",\n",
        "            \"parameters\": \"air temperature, winds, rain fall, water surface height (above reference datum), surface water temperature.\"\n",
        "        },\n",
        "        \"meteorological_data\": structured_met_data\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with open(output_filename, 'w') as f:\n",
        "            json.dump(output_data, f, indent=4)\n",
        "        print(f\"Meteorological data saved to {output_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving meteorological data to JSON: {e}\")\n",
        "else:\n",
        "    print(\"No meteorological data fetched to save.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b91637f"
      },
      "source": [
        "### Atmospheric Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4OYyjH-DeNd"
      },
      "source": [
        "#### Hourly Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa8a4827"
      },
      "outputs": [],
      "source": [
        "# hourly temperature forecast line graph -------------------------------------\n",
        "\n",
        "%pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import matplotlib.dates as mdates\n",
        "from datetime import date\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    # filter for the current date\n",
        "    today = date.today()\n",
        "    hourly_periods_today = [\n",
        "        period for period in hourly_periods\n",
        "        if datetime.fromisoformat(period['startTime']).date() == today\n",
        "    ]\n",
        "\n",
        "    if not hourly_periods_today:\n",
        "        print(\"No hourly forecast data available for the current date.\")\n",
        "    else:\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in hourly_periods_today]\n",
        "        temperatures = [period['temperature'] for period in hourly_periods_today]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(times, temperatures, marker='o')\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(f\"Temperature ({hourly_periods_today[0]['temperatureUnit']})\")\n",
        "        plt.title(f\"Hourly Temperature Forecast for {today.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "        # format x-axis to show time with appropriate intervals\n",
        "        ax = plt.gca()\n",
        "        formatter = mdates.DateFormatter('%H:%M')\n",
        "        ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "        # format tick locations\n",
        "        import numpy as np\n",
        "        hours = mdates.HourLocator(interval=3)  # set a tick every 3 hours\n",
        "        ax.xaxis.set_major_locator(hours)\n",
        "\n",
        "        plt.gcf().autofmt_xdate() # auto-format to prevent label overlapping\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"Hourly forecast data not available for visualization.\")\n",
        "\n",
        "\n",
        "\n",
        "# hourly apparent temperature forecast line graph ----------------------------\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    today = date.today() # filter for the current date\n",
        "    hourly_periods_today = [\n",
        "        period for period in hourly_periods\n",
        "        if datetime.fromisoformat(period['startTime']).date() == today\n",
        "    ]\n",
        "\n",
        "    if not hourly_periods_today:\n",
        "        print(\"No hourly forecast data available for the current date.\")\n",
        "    else:\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in hourly_periods_today]\n",
        "\n",
        "        # use apparent temperature if available, otherwise use temperature\n",
        "        temperatures = []\n",
        "        for period in hourly_periods_today:\n",
        "            apparent_temp = period.get('apparentTemperature', {}).get('value')\n",
        "            if apparent_temp is not None:\n",
        "                temperatures.append(apparent_temp)\n",
        "            else:\n",
        "                temperatures.append(period.get('temperature'))\n",
        "\n",
        "        # determine the unit\n",
        "        temp_unit = hourly_periods_today[0].get('temperatureUnit', '')\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(times, temperatures, marker='o')\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(f\"Temperature ({temp_unit})\") # label reflects whats plotted\n",
        "        plt.title(f\"Hourly Temperature (Apparent if available) Forecast for {today.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "        # format x-axis to show time with appropriate intervals\n",
        "        ax = plt.gca()\n",
        "        formatter = mdates.DateFormatter('%H:%M')\n",
        "        ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "        # format tick locations\n",
        "        import numpy as np\n",
        "        hours = mdates.HourLocator(interval=3)  # set a tick every 3 hours\n",
        "        ax.xaxis.set_major_locator(hours)\n",
        "\n",
        "        plt.gcf().autofmt_xdate() # auto-format to prevent label overlapping\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"Hourly forecast data not available for visualization.\")\n",
        "\n",
        "\n",
        "\n",
        "# hourly cloud cover forecast line graph -------------------------------------\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    # filter for the current date\n",
        "    today = date.today()\n",
        "    hourly_periods_today = [\n",
        "        period for period in hourly_periods\n",
        "        if datetime.fromisoformat(period['startTime']).date() == today\n",
        "    ]\n",
        "\n",
        "    if not hourly_periods_today:\n",
        "        print(\"No hourly forecast data available for the current date.\")\n",
        "    else:\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in hourly_periods_today]\n",
        "        # extract cloud cover - need to handle potential none values\n",
        "        cloud_cover_values = [period.get('cloudCover', {}).get('value') for period in hourly_periods_today]\n",
        "\n",
        "        # remove none values for plotting\n",
        "        times_filtered = [times[i] for i, val in enumerate(cloud_cover_values) if val is not None]\n",
        "        cloud_cover_values_filtered = [val for val in cloud_cover_values if val is not None]\n",
        "\n",
        "\n",
        "        if not cloud_cover_values_filtered:\n",
        "             print(\"Cloud Cover data not available for visualization for the current date.\")\n",
        "        else:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(times_filtered, cloud_cover_values_filtered, marker='o')\n",
        "            plt.xlabel(\"Time\")\n",
        "            plt.ylabel(\"Cloud Cover (%)\")\n",
        "            plt.title(f\"Hourly Cloud Cover Forecast for {today.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "            # format x-axis to show only time and set appropriate intervals\n",
        "            ax = plt.gca()\n",
        "            formatter = mdates.DateFormatter('%H:%M')\n",
        "            ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "            import numpy as np\n",
        "            hours = mdates.HourLocator(interval=3) # set a tick every 3 hours\n",
        "            ax.xaxis.set_major_locator(hours)\n",
        "\n",
        "\n",
        "            plt.gcf().autofmt_xdate() # format to prevent label overlapping\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "else:\n",
        "    print(\"Hourly forecast data not available for visualization.\")\n",
        "\n",
        "\n",
        "\n",
        "# hourly precipitation forecast probability line graph -----------------------\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    # filter for the current date\n",
        "    today = date.today()\n",
        "    hourly_periods_today = [\n",
        "        period for period in hourly_periods\n",
        "        if datetime.fromisoformat(period['startTime']).date() == today\n",
        "    ]\n",
        "\n",
        "    if not hourly_periods_today:\n",
        "        print(\"No hourly forecast data available for the current date.\")\n",
        "    else:\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in hourly_periods_today]\n",
        "        # extract probability of precipitation\n",
        "        precipitation_probs = [period.get('probabilityOfPrecipitation', {}).get('value', 0) for period in hourly_periods_today]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(times, precipitation_probs, marker='o')\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Probability of Precipitation (%)\")\n",
        "        plt.title(f\"Hourly Probability of Precipitation Forecast for {today.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "        # format x-axis to show only time and set appropriate intervals\n",
        "        ax = plt.gca()\n",
        "        formatter = mdates.DateFormatter('%H:%M')\n",
        "        ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "        import numpy as np\n",
        "        hours = mdates.HourLocator(interval=3)  # set a tick every 3 hours\n",
        "        ax.xaxis.set_major_locator(hours)\n",
        "\n",
        "\n",
        "        plt.gcf().autofmt_xdate() # auto-format to prevent labels overlapping\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"Hourly forecast data not available for visualization.\")\n",
        "\n",
        "\n",
        "\n",
        "# hourly humidity forecast line graph ----------------------------------------\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    # filter for the current date\n",
        "    today = date.today()\n",
        "    hourly_periods_today = [\n",
        "        period for period in hourly_periods\n",
        "        if datetime.fromisoformat(period['startTime']).date() == today\n",
        "    ]\n",
        "\n",
        "    if not hourly_periods_today:\n",
        "        print(\"No hourly forecast data available for the current date.\")\n",
        "    else:\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in hourly_periods_today]\n",
        "        # Extract relative humidity\n",
        "        humidity_values = [period.get('relativeHumidity', {}).get('value', 0) for period in hourly_periods_today]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(times, humidity_values, marker='o')\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Relative Humidity (%)\")\n",
        "        plt.title(f\"Hourly Relative Humidity Forecast for {today.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "        # format the x-axis to show only time and set appropriate intervals\n",
        "        ax = plt.gca()\n",
        "        formatter = mdates.DateFormatter('%H:%M')\n",
        "        ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "        import numpy as np\n",
        "        hours = mdates.HourLocator(interval=3)  # set a tick every 3 hours\n",
        "        ax.xaxis.set_major_locator(hours)\n",
        "\n",
        "\n",
        "        plt.gcf().autofmt_xdate() # auto-format to prevent labels overlapping\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"Hourly forecast data not available for visualization.\")\n",
        "\n",
        "\n",
        "\n",
        "# hourly visibility forecast line graph --------------------------------------\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    # filter for the current date\n",
        "    today = date.today()\n",
        "    hourly_periods_today = [\n",
        "        period for period in hourly_periods\n",
        "        if datetime.fromisoformat(period['startTime']).date() == today\n",
        "    ]\n",
        "\n",
        "    if not hourly_periods_today:\n",
        "        print(\"No hourly forecast data available for the current date.\")\n",
        "    else:\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in hourly_periods_today]\n",
        "        # extract visibility\n",
        "        visibility_values = []\n",
        "        visibility_unit = '' # initialize unit\n",
        "        for period in hourly_periods_today:\n",
        "            visibility_data = period.get('visibility', {})\n",
        "            value = visibility_data.get('value')\n",
        "            if value is not None:\n",
        "                visibility_values.append(value)\n",
        "                # capture the unit from the first available data point\n",
        "                if not visibility_unit and visibility_data.get('unitCode'):\n",
        "                    visibility_unit = visibility_data.get('unitCode')\n",
        "            else:\n",
        "                visibility_values.append(None) # append if data is missing\n",
        "\n",
        "        # remove None values for plotting\n",
        "        times_filtered = [times[i] for i, val in enumerate(visibility_values) if val is not None]\n",
        "        visibility_values_filtered = [val for val in visibility_values if val is not None]\n",
        "\n",
        "\n",
        "        if not visibility_values_filtered:\n",
        "             print(\"Visibility data not available for visualization for the current date.\")\n",
        "        else:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(times_filtered, visibility_values_filtered, marker='o')\n",
        "            plt.xlabel(\"Time\")\n",
        "            # set ylabel based on the captured unit\n",
        "            ylabel = \"Visibility\"\n",
        "            if visibility_unit:\n",
        "                 ylabel += f\" ({visibility_unit})\"\n",
        "\n",
        "            plt.ylabel(ylabel)\n",
        "            plt.title(f\"Hourly Visibility Forecast for {today.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "            # format x-axis to show only time and set appropriate intervals\n",
        "            ax = plt.gca()\n",
        "            formatter = mdates.DateFormatter('%H:%M')\n",
        "            ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "            import numpy as np\n",
        "            hours = mdates.HourLocator(interval=3)  # set a tick every 3 hours\n",
        "            ax.xaxis.set_major_locator(hours)\n",
        "\n",
        "            plt.gcf().autofmt_xdate() # auto-format for labels overlapping\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "else:\n",
        "    print(\"Hourly forecast data not available for visualization.\")\n",
        "\n",
        "\n",
        "\n",
        "# hourly dewpoint forecast line graph ----------------------------------------\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    # filter for the current date\n",
        "    today = date.today()\n",
        "    hourly_periods_today = [\n",
        "        period for period in hourly_periods\n",
        "        if datetime.fromisoformat(period['startTime']).date() == today\n",
        "    ]\n",
        "\n",
        "    if not hourly_periods_today:\n",
        "        print(\"No hourly forecast data available for the current date.\")\n",
        "    else:\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in hourly_periods_today]\n",
        "        # extract dewpoint - need to handle potential None values\n",
        "        dewpoint_values = [period.get('dewpoint', {}).get('value') for period in hourly_periods_today]\n",
        "\n",
        "        # convert dewpoint from C to F if temperature unit is F\n",
        "        if hourly_periods_today and hourly_periods_today[0].get('temperatureUnit') == 'F':\n",
        "             dewpoint_values = [(d * 9/5) + 32 if d is not None else None for d in dewpoint_values]\n",
        "             dewpoint_unit = 'F'\n",
        "        elif hourly_periods_today and hourly_periods_today[0].get('dewpoint') and hourly_periods_today[0]['dewpoint'].get('unitCode'):\n",
        "             dewpoint_unit = hourly_periods_today[0]['dewpoint'].get('unitCode')\n",
        "        else:\n",
        "             dewpoint_unit = ''\n",
        "\n",
        "\n",
        "        # remove None values for plotting\n",
        "        times_filtered = [times[i] for i, val in enumerate(dewpoint_values) if val is not None]\n",
        "        dewpoint_values_filtered = [val for val in dewpoint_values if val is not None]\n",
        "\n",
        "\n",
        "        if not dewpoint_values_filtered:\n",
        "             print(\"Dewpoint data not available for visualization for the current date.\")\n",
        "        else:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(times_filtered, dewpoint_values_filtered, marker='o')\n",
        "            plt.xlabel(\"Time\")\n",
        "            plt.ylabel(f\"Dewpoint (°{dewpoint_unit})\")\n",
        "            plt.title(f\"Hourly Dewpoint Forecast for {today.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "            # format x-axis to show only time and set appropriate intervals\n",
        "            ax = plt.gca()\n",
        "            formatter = mdates.DateFormatter('%H:%M')\n",
        "            ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "            import numpy as np\n",
        "            hours = mdates.HourLocator(interval=3)  # set a tick every 3 hours\n",
        "            ax.xaxis.set_major_locator(hours)\n",
        "\n",
        "\n",
        "            plt.gcf().autofmt_xdate() # format to prevent label overlapping\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "else:\n",
        "    print(\"Hourly forecast data not available for visualization.\")\n",
        "\n",
        "\n",
        "\n",
        "# hourly wind speed forecast line graph --------------------------------------\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    # filter for the current date\n",
        "    today = date.today()\n",
        "    hourly_periods_today = [\n",
        "        period for period in hourly_periods\n",
        "        if datetime.fromisoformat(period['startTime']).date() == today\n",
        "    ]\n",
        "\n",
        "    if not hourly_periods_today:\n",
        "        print(\"No hourly forecast data available for the current date.\")\n",
        "    else:\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in hourly_periods_today]\n",
        "        # extract wind speed\n",
        "        wind_speeds = []\n",
        "        for period in hourly_periods_today:\n",
        "            # for cases when windSpeed is 0\n",
        "            speed_str = period.get('windSpeed', '0 mph').split(' ')[0]\n",
        "            try:\n",
        "                wind_speeds.append(int(speed_str))\n",
        "            except ValueError:\n",
        "                # for cases when windSpeed is a range; takes the first number\n",
        "                 try:\n",
        "                     wind_speeds.append(int(speed_str.split(' to ')[0]))\n",
        "                 except ValueError:\n",
        "                     wind_speeds.append(0) # default to 0 if parsing fails\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(times, wind_speeds, marker='o')\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Wind Speed (mph)\")\n",
        "        plt.title(f\"Hourly Wind Speed Forecast for {today.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "        # format x-axis to show only time and set appropriate intervals\n",
        "        ax = plt.gca()\n",
        "        formatter = mdates.DateFormatter('%H:%M')\n",
        "        ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "        import numpy as np\n",
        "        hours = mdates.HourLocator(interval=3)  # set a tick every 3 hours\n",
        "        ax.xaxis.set_major_locator(hours)\n",
        "\n",
        "\n",
        "        plt.gcf().autofmt_xdate() # auto-format to prevent labels overlapping\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"Hourly forecast data not available for visualization.\")\n",
        "\n",
        "\n",
        "\n",
        "# hourly wind gust forecast line graph ---------------------------------------\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    # filter for the current date\n",
        "    today = date.today()\n",
        "    hourly_periods_today = [\n",
        "        period for period in hourly_periods\n",
        "        if datetime.fromisoformat(period['startTime']).date() == today\n",
        "    ]\n",
        "\n",
        "    if not hourly_periods_today:\n",
        "        print(\"No hourly forecast data available for the current date.\")\n",
        "    else:\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in hourly_periods_today]\n",
        "        # extract windGust\n",
        "        wind_gusts = []\n",
        "        for period in hourly_periods_today:\n",
        "            gust_str = period.get('windGust')\n",
        "            if gust_str: # check if windGust exists and is not None/empty\n",
        "                try:\n",
        "                    # for when windGust is a number or a range\n",
        "                    if ' to ' in gust_str:\n",
        "                        wind_gusts.append(int(gust_str.split(' to ')[0]))\n",
        "                    else:\n",
        "                        # assume unit is separated by space\n",
        "                        wind_gusts.append(int(gust_str.split(' ')[0]))\n",
        "                except (ValueError, IndexError):\n",
        "                    wind_gusts.append(0) # default to 0 if parsing fails\n",
        "            else:\n",
        "                wind_gusts.append(0) # append 0 if windGust is missing\n",
        "\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(times, wind_gusts, marker='o')\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Wind Gust (mph)\") # changed label to Wind Gust\n",
        "        plt.title(f\"Hourly Wind Gust Forecast for {today.strftime('%Y-%m-%d')}\") # changed title\n",
        "\n",
        "        # set the y-axis limit to start at 0\n",
        "        plt.ylim(bottom=0)\n",
        "\n",
        "        # format x-axis to show only time and set appropriate intervals\n",
        "        ax = plt.gca()\n",
        "        formatter = mdates.DateFormatter('%H:%M')\n",
        "        ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "        import numpy as np\n",
        "        hours = mdates.HourLocator(interval=3)  # set a tick every 3 hours\n",
        "        ax.xaxis.set_major_locator(hours)\n",
        "\n",
        "\n",
        "        plt.gcf().autofmt_xdate() # auto-format to prevent labels overlapping\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"Hourly forecast data not available for visualization.\")\n",
        "\n",
        "\n",
        "\n",
        "# hourly sky cover forecast line graph --------------------------------------\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    # filter for the current date\n",
        "    today = date.today()\n",
        "    hourly_periods_today = [\n",
        "        period for period in hourly_periods\n",
        "        if datetime.fromisoformat(period['startTime']).date() == today\n",
        "    ]\n",
        "\n",
        "    if not hourly_periods_today:\n",
        "        print(\"No hourly forecast data available for the current date.\")\n",
        "    else:\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in hourly_periods_today]\n",
        "        # extract skyCover - need to handle potential None values\n",
        "        sky_cover_values = [period.get('skyCover', {}).get('value') for period in hourly_periods_today]\n",
        "\n",
        "        # remove None values for plotting\n",
        "        times_filtered = [times[i] for i, val in enumerate(sky_cover_values) if val is not None]\n",
        "        sky_cover_values_filtered = [val for val in sky_cover_values if val is not None]\n",
        "\n",
        "        if not sky_cover_values_filtered:\n",
        "             print(\"Sky Cover data not available for visualization for the current date.\")\n",
        "        else:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(times_filtered, sky_cover_values_filtered, marker='o')\n",
        "            plt.xlabel(\"Time\")\n",
        "            plt.ylabel(\"Sky Cover (%)\")\n",
        "            plt.title(f\"Hourly Sky Cover Forecast for {today.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "            # format x-axis to show only time and set appropriate intervals\n",
        "            ax = plt.gca()\n",
        "            formatter = mdates.DateFormatter('%H:%M')\n",
        "            ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "            import numpy as np\n",
        "            hours = mdates.HourLocator(interval=3)  # set a tick every 3 hours\n",
        "            ax.xaxis.set_major_locator(hours)\n",
        "\n",
        "\n",
        "            plt.gcf().autofmt_xdate() # format to prevent label overlapping\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "else:\n",
        "    print(\"Hourly forecast data not available for visualization.\")\n",
        "\n",
        "\n",
        "\n",
        "# hourly heat / UV index forecast line graph ---------------------------------\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    # filter for the current date\n",
        "    today = date.today()\n",
        "    hourly_periods_today = [\n",
        "        period for period in hourly_periods\n",
        "        if datetime.fromisoformat(period['startTime']).date() == today\n",
        "    ]\n",
        "\n",
        "    if not hourly_periods_today:\n",
        "        print(\"No hourly forecast data available for the current date.\")\n",
        "    else:\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in hourly_periods_today]\n",
        "        # extract heat index - need to handle potential None values\n",
        "        heat_index_values = [period.get('heatIndex', {}).get('value') for period in hourly_periods_today]\n",
        "\n",
        "        # determine the unit if available\n",
        "        heat_index_unit = ''\n",
        "        if hourly_periods_today and hourly_periods_today[0].get('heatIndex') and hourly_periods_today[0]['heatIndex'].get('unitCode'):\n",
        "             heat_index_unit = hourly_periods_today[0]['heatIndex'].get('unitCode')\n",
        "\n",
        "\n",
        "        # remove None values for plotting\n",
        "        times_filtered = [times[i] for i, val in enumerate(heat_index_values) if val is not None]\n",
        "        heat_index_values_filtered = [val for val in heat_index_values if val is not None]\n",
        "\n",
        "\n",
        "        if not heat_index_values_filtered:\n",
        "             print(\"Heat Index data not available for visualization for the current date.\")\n",
        "        else:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(times_filtered, heat_index_values_filtered, marker='o')\n",
        "            plt.xlabel(\"Time\")\n",
        "            plt.ylabel(f\"Heat Index (°{heat_index_unit})\")\n",
        "            plt.title(f\"Hourly Heat Index Forecast for {today.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "            # format x-axis to show only time and set appropriate intervals\n",
        "            ax = plt.gca()\n",
        "            formatter = mdates.DateFormatter('%H:%M')\n",
        "            ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "            import numpy as np\n",
        "            hours = mdates.HourLocator(interval=3)  # set a tick every 3 hours\n",
        "            ax.xaxis.set_major_locator(hours)\n",
        "\n",
        "\n",
        "            plt.gcf().autofmt_xdate() # format to prevent label overlapping\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "else:\n",
        "    print(\"Hourly forecast data not available for visualization.\")\n",
        "\n",
        "\n",
        "\n",
        "# hourly snowfall amount forecast line graph ---------------------------------\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    # filter for the current date\n",
        "    today = date.today()\n",
        "    hourly_periods_today = [\n",
        "        period for period in hourly_periods\n",
        "        if datetime.fromisoformat(period['startTime']).date() == today\n",
        "    ]\n",
        "\n",
        "    if not hourly_periods_today:\n",
        "        print(\"No hourly forecast data available for the current date.\")\n",
        "    else:\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in hourly_periods_today]\n",
        "        # extract snowfallAmount\n",
        "        snowfall_values = []\n",
        "        snowfall_unit = ''\n",
        "        for period in hourly_periods_today:\n",
        "            snowfall_data = period.get('snowfallAmount', {})\n",
        "            value = snowfall_data.get('value')\n",
        "            if value is not None:\n",
        "                snowfall_values.append(value)\n",
        "                # capture the unit from the first available data point\n",
        "                if not snowfall_unit and snowfall_data.get('unitCode'):\n",
        "                    snowfall_unit = snowfall_data.get('unitCode')\n",
        "            else:\n",
        "                snowfall_values.append(0) # append 0 if data is missing\n",
        "\n",
        "\n",
        "        if not any(snowfall_values): # check for any snowfall predictions\n",
        "             print(\"Snowfall data not available or no snowfall predicted for the current date.\")\n",
        "        else:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(times, snowfall_values, marker='o')\n",
        "            plt.xlabel(\"Time\")\n",
        "            plt.ylabel(f\"Snowfall Amount ({snowfall_unit})\")\n",
        "            plt.title(f\"Hourly Snowfall Amount Forecast for {today.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "            # format x-axis to show only time and set appropriate intervals\n",
        "            ax = plt.gca()\n",
        "            formatter = mdates.DateFormatter('%H:%M')\n",
        "            ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "            import numpy as np\n",
        "            hours = mdates.HourLocator(interval=3)  # set a tick every 3 hours\n",
        "            ax.xaxis.set_major_locator(hours)\n",
        "\n",
        "\n",
        "            plt.gcf().autofmt_xdate() # format to prevent label overlapping\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "else:\n",
        "    print(\"Hourly forecast data not available for visualization.\")\n",
        "\n",
        "\n",
        "\n",
        "# hourly ice accumulation forecast line graph --------------------------------\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    # filter for the current date\n",
        "    today = date.today()\n",
        "    hourly_periods_today = [\n",
        "        period for period in hourly_periods\n",
        "        if datetime.fromisoformat(period['startTime']).date() == today\n",
        "    ]\n",
        "\n",
        "    if not hourly_periods_today:\n",
        "        print(\"No hourly forecast data available for the current date.\")\n",
        "    else:\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in hourly_periods_today]\n",
        "        # extract iceAccumulation\n",
        "        ice_accumulation_values = []\n",
        "        ice_accumulation_unit = ''\n",
        "        for period in hourly_periods_today:\n",
        "            ice_data = period.get('iceAccumulation', {})\n",
        "            value = ice_data.get('value')\n",
        "            if value is not None:\n",
        "                ice_accumulation_values.append(value)\n",
        "                # capture the unit from the first available data point\n",
        "                if not ice_accumulation_unit and ice_data.get('unitCode'):\n",
        "                    ice_accumulation_unit = ice_data.get('unitCode')\n",
        "            else:\n",
        "                # append 0 if data is missing\n",
        "                ice_accumulation_values.append(0)\n",
        "\n",
        "        # check if there is any ice accumulation predicted\n",
        "        if not any(ice_accumulation_values):\n",
        "             print(\"Ice accumulation data not available or no ice accumulation predicted for the current date.\")\n",
        "        else:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(times, ice_accumulation_values, marker='o')\n",
        "            plt.xlabel(\"Time\")\n",
        "            plt.ylabel(f\"Ice Accumulation ({ice_accumulation_unit})\")\n",
        "            plt.title(f\"Hourly Ice Accumulation Forecast for {today.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "            # format x-axis to show only time and set appropriate intervals\n",
        "            ax = plt.gca()\n",
        "            formatter = mdates.DateFormatter('%H:%M')\n",
        "            ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "            import numpy as np\n",
        "            hours = mdates.HourLocator(interval=3)  # set a tick every 3 hours\n",
        "            ax.xaxis.set_major_locator(hours)\n",
        "\n",
        "\n",
        "            plt.gcf().autofmt_xdate() # format to prevent label overlapping\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "else:\n",
        "    print(\"Hourly forecast data not available for visualization.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kvmQNgtJRpK"
      },
      "source": [
        "#### Hourly Container +7-Day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de35e27c"
      },
      "outputs": [],
      "source": [
        "# hourly forecast container for 7-days\n",
        "\n",
        "import json\n",
        "from datetime import datetime # Import datetime for parsing the string timestamps\n",
        "\n",
        "\n",
        "if weather_data_result and 'hourly_forecast' in weather_data_result:\n",
        "    hourly_periods = weather_data_result['hourly_forecast']['properties']['periods']\n",
        "\n",
        "    # convert datetime objects to strings for JSON serialization\n",
        "    # for period in hourly_periods:\n",
        "    #     period['startTime'] = period['startTime'].isoformat()\n",
        "    #     period['endTime'] = period['endTime'].isoformat()\n",
        "\n",
        "    print(\"\\n--- Hourly Forecast ---\")\n",
        "    for period in hourly_periods:\n",
        "        # Parse the string timestamps into datetime objects for printing\n",
        "        start_time_dt = datetime.fromisoformat(period['startTime'])\n",
        "        print(f\"\\nTime: {start_time_dt.strftime('%Y-%m-%d %H:%M')}\")\n",
        "        print(f\"  Temperature: {period.get('temperature')}°{period.get('temperatureUnit', '')}\")\n",
        "\n",
        "        if period.get('windChill') and period['windChill'].get('value') is not None:\n",
        "             print(f\"  Wind Chill: {period['windChill']['value']}°{period['windChill'].get('unitCode', '')}\")\n",
        "\n",
        "        if period.get('heatIndex') and period['heatIndex'].get('value') is not None:\n",
        "             print(f\"  Heat Index: {period['heatIndex']['value']}°{period['heatIndex'].get('unitCode', '')}\")\n",
        "        print(f\"  Wind Speed: {period.get('windSpeed', 'N/A')}\")\n",
        "        print(f\"  Wind Direction: {period.get('windDirection', 'N/A')}\")\n",
        "\n",
        "        if period.get('cloudCover') and period['cloudCover'].get('value') is not None:\n",
        "             print(f\"  Cloud Cover: {period['cloudCover']['value']}%\")\n",
        "\n",
        "        if period.get('probabilityOfPrecipitation') and period['probabilityOfPrecipitation'].get('value') is not None:\n",
        "             print(f\"  Probability of Precipitation: {period['probabilityOfPrecipitation']['value']}%\")\n",
        "\n",
        "        if period.get('dewpoint') and period['dewpoint'].get('value') is not None:\n",
        "             # convert dewpoint from C to F if temperature unit is F\n",
        "             dewpoint_value = period['dewpoint']['value']\n",
        "             dewpoint_unit = period['dewpoint'].get('unitCode', '')\n",
        "             if period.get('temperatureUnit') == 'F' and dewpoint_unit == 'wmoUnit:degC':\n",
        "                 dewpoint_value = (dewpoint_value * 9/5) + 32\n",
        "                 dewpoint_unit = 'F' # update unit to F\n",
        "\n",
        "             # if the original unit is already F (unlikely)\n",
        "             elif period.get('temperatureUnit') == 'F' and dewpoint_unit == 'wmoUnit:degF':\n",
        "                 dewpoint_unit = 'F'\n",
        "\n",
        "             print(f\"  Dewpoint: {dewpoint_value:.0f}°{dewpoint_unit}\")\n",
        "\n",
        "\n",
        "        if period.get('relativeHumidity') and period['relativeHumidity'].get('value') is not None:\n",
        "             print(f\"  Relative Humidity: {period['relativeHumidity']['value']}%\")\n",
        "\n",
        "        print(f\"  Short Forecast: {period.get('shortForecast', 'N/A')}\")\n",
        "\n",
        "\n",
        "    # save hourly forecast data to JSON file\n",
        "    hourly_output_filename = \"noaa_hourly_7day_forecast.json\"\n",
        "    try:\n",
        "        with open(hourly_output_filename, 'w') as f:\n",
        "            json.dump(hourly_periods, f, indent=4)\n",
        "        print(f\"\\nHourly forecast data saved to {hourly_output_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError saving hourly forecast data to JSON: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"Hourly forecast data not available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvKrIlDv3qB2"
      },
      "source": [
        "#### 7-Day Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4be4555"
      },
      "outputs": [],
      "source": [
        "# 7-day temperature bar graph ------------------------------------------------\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "if weather_data_result and 'forecast' in weather_data_result:\n",
        "    forecast_periods = weather_data_result['forecast']['properties']['periods']\n",
        "\n",
        "    if not forecast_periods:\n",
        "        print(\"7-day forecast data not available for visualization.\")\n",
        "    else:\n",
        "        # extract times, temperatures, and daytime status for each period\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in forecast_periods]\n",
        "        temperatures = [period['temperature'] for period in forecast_periods]\n",
        "        is_daytime = [period['isDaytime'] for period in forecast_periods]\n",
        "\n",
        "        # eetermine the unit\n",
        "        temp_unit = forecast_periods[0].get('temperatureUnit', '')\n",
        "\n",
        "        # define colors for day and night\n",
        "        colors = ['skyblue' if day else 'darkblue' for day in is_daytime]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        # plot bars with different colors based on daytime status\n",
        "        plt.bar(times, temperatures, width=0.4, color=colors)\n",
        "        plt.xlabel(\"Day\")\n",
        "        plt.ylabel(f\"Temperature ({temp_unit})\")\n",
        "        plt.title(\"7-Day Temperature Forecast\")\n",
        "\n",
        "        # format the x-axis to show days of the week\n",
        "        ax = plt.gca()\n",
        "        formatter = mdates.DateFormatter('%A')\n",
        "        ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "        # set tick locations (one tick per day)\n",
        "        ax.xaxis.set_major_locator(mdates.DayLocator())\n",
        "\n",
        "\n",
        "        plt.gcf().autofmt_xdate() # auto-format to prevent labels overlapping\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"7-day forecast data not available for visualization.\")\n",
        "\n",
        "\n",
        "# 7-day precipitation probability line graph ---------------------------------\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "if weather_data_result and 'forecast' in weather_data_result:\n",
        "    forecast_periods = weather_data_result['forecast']['properties']['periods']\n",
        "\n",
        "    if not forecast_periods:\n",
        "        print(\"7-day forecast data not available for visualization.\")\n",
        "    else:\n",
        "        # extract times and probability of precipitation for each period\n",
        "        times = [datetime.fromisoformat(period['startTime']) for period in forecast_periods]\n",
        "        # extract probability of precipitation, handling potential None values\n",
        "        precipitation_probs = [period.get('probabilityOfPrecipitation', {}).get('value', 0) for period in forecast_periods]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(times, precipitation_probs, marker='o')\n",
        "        plt.xlabel(\"Day\")\n",
        "        plt.ylabel(\"Probability of Precipitation (%)\")\n",
        "        plt.title(\"7-Day Probability of Precipitation Forecast\")\n",
        "\n",
        "        # format the x-axis to show days of the week\n",
        "        ax = plt.gca()\n",
        "        formatter = mdates.DateFormatter('%A')\n",
        "        ax.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "        # set tick locations (one tick per day)\n",
        "        ax.xaxis.set_major_locator(mdates.DayLocator())\n",
        "\n",
        "\n",
        "        plt.gcf().autofmt_xdate() # auto-format to prevent labels overlapping\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"7-day forecast data not available for visualization.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbAeqA7eDSLi"
      },
      "source": [
        "#### 7-Day Container +Alerts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "011a45ec"
      },
      "outputs": [],
      "source": [
        "# 7-day forecast container\n",
        "\n",
        "import json\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "if weather_data_result and 'forecast' in weather_data_result:\n",
        "    forecast_periods = weather_data_result['forecast']['properties']['periods']\n",
        "    print(\"--- 7-Day Forecast ---\")\n",
        "\n",
        "    # Print the total number of active weather alerts found\n",
        "    if parsed_alerts:\n",
        "        print(f\"Total active weather alerts found for {user_location}: {len(parsed_alerts)}\")\n",
        "    else:\n",
        "        print(f\"No active weather alerts found for {user_location}.\")\n",
        "\n",
        "    for period in forecast_periods:\n",
        "        # convert period times to datetime objects (assuming ISO 8601 format)\n",
        "        start_time = datetime.fromisoformat(period['startTime'])\n",
        "        end_time = datetime.fromisoformat(period['endTime'])\n",
        "\n",
        "        print(f\"\\n{period['name']}:\")\n",
        "        print(f\"  Temperature: {period.get('temperature')}°{period.get('temperatureUnit', '')}\")\n",
        "        print(f\"  Short Forecast: {period.get('shortForecast', 'N/A')}\")\n",
        "        print(f\"  Detailed Forecast: {period.get('detailedForecast', 'N/A')}\")\n",
        "        print(f\"  Wind Speed: {period.get('windSpeed', 'N/A')}\")\n",
        "        print(f\"  Wind Direction: {period.get('windDirection', 'N/A')}\")\n",
        "\n",
        "        # include probability of precipitation\n",
        "        if period.get('probabilityOfPrecipitation') and period['probabilityOfPrecipitation'].get('value') is not None:\n",
        "             print(f\"  Probability of Precipitation: {period['probabilityOfPrecipitation']['value']}%\")\n",
        "\n",
        "        # check for relevant active alerts within forecast period\n",
        "        relevant_alerts = []\n",
        "        if parsed_alerts:\n",
        "            for alert in parsed_alerts:\n",
        "                alert_effective = datetime.fromisoformat(alert.get('effective')) if alert.get('effective') else None\n",
        "                alert_expires = datetime.fromisoformat(alert.get('expires')) if alert.get('expires') else None\n",
        "\n",
        "                # check if alert times overlap with the forecast period\n",
        "                if alert_effective and alert_expires:\n",
        "                    # an alert is relevant if it starts before or during the period and ends after or during the period\n",
        "                    if (alert_effective <= end_time and alert_expires >= start_time):\n",
        "                         relevant_alerts.append(alert)\n",
        "                # alert with no explicit end time\n",
        "                elif alert_effective and not alert_expires:\n",
        "                     if alert_effective <= end_time:\n",
        "                          relevant_alerts.append(alert)\n",
        "                # alert with no explicit start time (uncommon)\n",
        "                elif not alert_effective and alert_expires:\n",
        "                     if alert_expires >= start_time:\n",
        "                           relevant_alerts.append(alert)\n",
        "                # alert with no effective or expires time\n",
        "                else:\n",
        "                     pass\n",
        "\n",
        "\n",
        "        if relevant_alerts:\n",
        "            print(\"  Active Alerts:\")\n",
        "            for rel_alert in relevant_alerts:\n",
        "                print(f\"    - Event: {rel_alert.get('event', 'N/A')}\")\n",
        "                print(f\"      Headline: {rel_alert.get('headline', 'N/A')}\")\n",
        "\n",
        "    # save 7-day forecast data to JSON file\n",
        "    forecast_output_filename = \"noaa_7day_forecast.json\"\n",
        "    try:\n",
        "        with open(forecast_output_filename, 'w') as f:\n",
        "            json.dump(forecast_periods, f, indent=4)\n",
        "        print(f\"\\n7-day forecast data saved to {forecast_output_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError saving 7-day forecast data to JSON: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"Forecast data not available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3a09464"
      },
      "source": [
        "#### Alerts Container\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5890883a"
      },
      "outputs": [],
      "source": [
        "# active weather alerts container\n",
        "\n",
        "# iterate through the parsed alerts\n",
        "if parsed_alerts:\n",
        "    print(f\"--- Active Weather Alerts for {user_location} ---\")\n",
        "    for alert in parsed_alerts:\n",
        "        print(f\"\\nEvent: {alert.get('event', 'N/A')}\")\n",
        "        print(f\"Headline: {alert.get('headline', 'N/A')}\")\n",
        "        print(f\"Description: {alert.get('description', 'N/A')}\")\n",
        "        print(f\"Effective: {alert.get('effective', 'N/A')}\")\n",
        "        print(f\"Expires: {alert.get('expires', 'N/A')}\")\n",
        "        print(\"-\" * 20) # separator for clarity\n",
        "else:\n",
        "    print(f\"No active weather alerts found for {user_location}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1477fe6"
      },
      "source": [
        "#### Air Quality Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "191da56c"
      },
      "outputs": [],
      "source": [
        "# AQ (air quality) graph\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "if aq_data:\n",
        "    # convert list of dictionaries to a pandas DataFrame for easier handling\n",
        "    aq_df = pd.DataFrame(aq_data)\n",
        "\n",
        "    if not aq_df.empty:\n",
        "      # extract date from the first entry (assuming all entries have same date)\n",
        "      observation_date = aq_df['DateObserved'].iloc[0] if 'DateObserved' in aq_df.columns else \"Unknown Date\"\n",
        "\n",
        "      # create a bar chart for AQI by Parameter\n",
        "      plt.figure(figsize=(10, 6))\n",
        "      plt.bar(aq_df['ParameterName'], aq_df['AQI'], color=['skyblue', 'lightgreen', 'salmon'])\n",
        "      plt.xlabel(\"Parameter\")\n",
        "      plt.ylabel(\"AQI (Air Quality Index)\")\n",
        "      # add the date to the title\n",
        "      plt.title(f\"Air Quality Index by Parameter on {observation_date}\")\n",
        "      plt.ylim(0, aq_df['AQI'].max() * 1.2) # set y-axis limit a bit above the max AQI\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "    else:\n",
        "      print(\"Air quality data is empty, cannot create visualizations.\")\n",
        "else:\n",
        "  print(\"Air quality data not available for visualization.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ_PZI6KhNdG"
      },
      "source": [
        "#### Air Quality Container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ3z4nkQg4WY"
      },
      "outputs": [],
      "source": [
        "# air quality container\n",
        "\n",
        "if aq_data:\n",
        "    print(\"--- Air Quality Data ---\")\n",
        "    for entry in aq_data:\n",
        "        print(f\"\\nDate Observed: {entry.get('DateObserved', 'N/A')}\")\n",
        "        print(f\"Hour Observed: {entry.get('HourObserved', 'N/A')} {entry.get('LocalTimeZone', 'N/A')}\")\n",
        "        print(f\"Reporting Area: {entry.get('ReportingArea', 'N/A')}\")\n",
        "        print(f\"Parameter Name: {entry.get('ParameterName', 'N/A')}\")\n",
        "        print(f\"AQI: {entry.get('AQI', 'N/A')}\")\n",
        "        # access the Name from the Category dictionary\n",
        "        category_name = entry.get('Category', {}).get('Name', 'N/A')\n",
        "        print(f\"Category: {category_name}\")\n",
        "        print(\"-\" * 20) # separator for clarity\n",
        "else:\n",
        "    print(\"Air quality data not available.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ebSzmQPSDjS9",
        "J3D_nNAcDU1i",
        "9b91637f"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}